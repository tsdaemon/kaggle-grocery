{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import gc\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "from importlib import reload\n",
    "import date\n",
    "reload(date)\n",
    "from date import *\n",
    "import model\n",
    "reload(model)\n",
    "from model import *\n",
    "from metric import get_weights, NWRMSLE_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading batch from position 110000000, batch size 10000000...\n",
      "Filtering 10000000...\n",
      "Filtered 8659998, mapping...\n",
      "Mapped, reducing...\n",
      "Batch done.\n",
      "================================================================================\n",
      "Reading batch from position 120000000, batch size 10000000...\n",
      "Filtering 5497041...\n",
      "Filtered 5497041, mapping...\n",
      "Mapped, reducing...\n",
      "Batch done.\n",
      "End of dataset is found.\n"
     ]
    }
   ],
   "source": [
    "df = load_data_in_date_range('./data/train_processed.csv', '2017-04-04', '2017-08-15', 110000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading additional datasets\n"
     ]
    }
   ],
   "source": [
    "print('Reading additional datasets')\n",
    "items = pd.read_csv('./data/items_encoded.csv')\n",
    "stores = pd.read_csv('./data/stores_encoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting and joining additional data\n"
     ]
    }
   ],
   "source": [
    "print('Converting and joining additional data')\n",
    "df = convert_unit_sales(df)\n",
    "df = fill_empty_sales(df)\n",
    "df, cols_categories = extend_dataset(df, items, stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date             int16\n",
       "store_nbr        int16\n",
       "item_nbr         int32\n",
       "id             float64\n",
       "unit_sales     float32\n",
       "onpromotion       bool\n",
       "weekday          int16\n",
       "weekend           bool\n",
       "salary            bool\n",
       "family           int16\n",
       "class            int16\n",
       "perishable        bool\n",
       "city             int16\n",
       "state            int16\n",
       "type             int16\n",
       "cluster          int16\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding mean target encoding\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# cat_features = items_cols + stores_cols + ['store_nbr','item_nbr','onpromotion']\n",
    "# combinations = list(itertools.combinations(cat_features, 1)) + \\\n",
    "# [['store_nbr','item_nbr'], ['store_nbr','item_nbr', 'onpromotion']]\n",
    "\n",
    "combinations = [['item_nbr'],\n",
    "                ['store_nbr','item_nbr'], \n",
    "                ['store_nbr','item_nbr', 'onpromotion']]\n",
    "print('Adding mean target encoding')\n",
    "\n",
    "df, cols_mean = add_mean_encoding(df, combinations)\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "ranges2 = get_one_week_ranges(16, get_date_index_parse('2017-08-15'))\n",
    "df, cols_mean2 = add_mean_encoding(df, combinations, ranges=ranges2, prefix='1week_')\n",
    "cols_mean += cols_mean2\n",
    "df.reset_index(inplace=True)\n",
    "df = optimize_df_types(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding lagged features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/pandas/core/generic.py:3643: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/home/ubuntu/grocery/model.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_prev[colname] = df_prev['unit_sales']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding lag 12...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7b6b7cc04543>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Adding lagged features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_nbr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'store_nbr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'unit_sales'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_lagged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_lagged\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdf_prev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/grocery/model.py\u001b[0m in \u001b[0;36mfill_lagged\u001b[0;34m(df, df_prev, start_lagged, end_lagged, verbose)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mcolname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'unit_sales(t-{})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_lagged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mdf_prev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_prev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unit_sales'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_prev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_nbr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'store_nbr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_nbr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'store_nbr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mdf_prev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   5345\u001b[0m                      \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5346\u001b[0m                      \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5347\u001b[0;31m                      copy=copy, indicator=indicator, validate=validate)\n\u001b[0m\u001b[1;32m   5348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     56\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                          validate=validate)\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m                 self.left, self.right)\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mjoin_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_join_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mldata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_join_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m             (left_indexer,\n\u001b[0;32m--> 748\u001b[0;31m              right_indexer) = self._get_join_indexers()\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_join_indexers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                                   \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m                                   how=self.how)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_join_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_join_indexers\u001b[0;34m(left_keys, right_keys, sort, how, **kwargs)\u001b[0m\n\u001b[1;32m   1064\u001b[0m     \u001b[0mjoin_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_join_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjoin_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/join.pyx\u001b[0m in \u001b[0;36mpandas._libs.join.left_outer_join\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Adding lagged features')\n",
    "df_prev = df[['item_nbr', 'store_nbr', 'date', 'unit_sales']]\n",
    "df, cols_lagged = fill_lagged(df, df_prev, 12, 14, True)\n",
    "del df_prev\n",
    "gc.collect()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!telegram-send \"Lagged and mean extraction is ready, starting validation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_by_date(df, '2017-05-16', '2017-08-15')\n",
    "gc.collect()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [('2017-05-16', '2017-06-30', '2017-07-01', '2017-07-15'),\n",
    "         ('2017-06-01', '2017-07-15', '2017-07-16', '2017-07-31'),\n",
    "         ('2017-06-16', '2017-07-31', '2017-08-01', '2017-08-15')]\n",
    "\n",
    "param = {\n",
    "    'num_leaves':30,\n",
    "    'objective':'regression_l2',\n",
    "    'metric':'l2_root',\n",
    "    'num_threads':4\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = {'perishable', 'type', 'city', 'family',\n",
    "            'mean_unit_sales_by_(state)', 'mean_unit_sales_by_(city)',\n",
    "            'mean_unit_sales_by_(cluster)', 'mean_unit_sales_by_(type)'}\n",
    "def remove_cols(cols, remove):\n",
    "    return list(set(cols) - set(remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_unit_sales_by_(item_nbr)',\n",
       " 'mean_unit_sales_by_(store_nbr+item_nbr)',\n",
       " 'mean_unit_sales_by_(store_nbr+item_nbr+onpromotion)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cols_lagged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-190f61615a94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m          ]\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mx_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols_categories\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'onpromotion'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcols_lagged\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcols_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#x_cols = remove_cols(x_cols, to_remove)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cols_lagged' is not defined"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "bsts = []\n",
    "mean_c = ['mean_unit_sales_by_(store_nbr+item_nbr+onpromotion)', \n",
    "          #'mean_unit_sales_by_(item_nbr)', \n",
    "          #'mean_unit_sales_by_(store_nbr+item_nbr)',\n",
    "          #'mean_unit_sales_by_(store_nbr)'\n",
    "         ]\n",
    "\n",
    "x_cols = cols_categories + ['onpromotion'] + cols_lagged + cols_mean\n",
    "#x_cols = remove_cols(x_cols, to_remove)\n",
    "\n",
    "cat_cols = cols_categories + ['onpromotion']\n",
    "#cat_cols = remove_cols(cat_cols, to_remove)\n",
    "\n",
    "for train_start, train_end, test_start, test_end in folds:\n",
    "    print(\"Extracting fold...\")\n",
    "    train = extract_by_date(df, train_start, train_end)\n",
    "    test= extract_by_date(df, test_start, test_end)\n",
    "    \n",
    "    print(\"Preparing train...\")\n",
    "    train_X = train[x_cols].fillna(0.0)\n",
    "    train_y = train['unit_sales']\n",
    "    train_weights = get_weights(train['item_nbr'])\n",
    "    del train\n",
    "    gc.collect()\n",
    "    train_dataset = lgb.Dataset(train_X, label=train_y, weight=train_weights)\n",
    "    del train_X\n",
    "    del train_y\n",
    "    del train_weights\n",
    "    gc.collect()\n",
    "    \n",
    "    print(\"Preparing test...\")\n",
    "    test_X = test[x_cols].fillna(0.0)\n",
    "    test_y = test['unit_sales']\n",
    "    test_weights = get_weights(test['item_nbr'])\n",
    "    del test\n",
    "    gc.collect()\n",
    "    test_dataset = lgb.Dataset(test_X, label=test_y, weight=test_weights, reference=train_dataset)\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    bst = lgb.train(param, \n",
    "                    train_dataset, \n",
    "                    150,\n",
    "                    valid_sets=[test_dataset], \n",
    "                    early_stopping_rounds=10, \n",
    "                    verbose_eval=True, \n",
    "                    feature_name=x_cols, \n",
    "                    categorical_feature=cat_cols)\n",
    "    \n",
    "    del test_dataset\n",
    "    del train_dataset\n",
    "    gc.collect()\n",
    "    \n",
    "    test_y_pred = bst.predict(test_X)\n",
    "    error = NWRMSLE_log(test_y_pred, test_y, test_weights)\n",
    "    print('Validation error: {}'.format(error))\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    errors.append(error)\n",
    "    bsts.append(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = np.mean(errors)\n",
    "!telegram-send \"Mean lagged xgb validation finished. Results: $mean_error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = list(sorted(zip(bsts[0].feature_importance(), x_cols), key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(bsts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/lightgbm/basic.py:1007: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['city', 'class', 'cluster', 'family', 'onpromotion', 'perishable', 'salary', 'state', 'type', 'weekday', 'weekend']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    }
   ],
   "source": [
    "param['task'] = 'prediction'\n",
    "start = '2017-07-01'\n",
    "end = '2017-08-15'\n",
    "num_round = 150\n",
    "train = extract_by_date(df, start, end)\n",
    "train_X = train[x_cols]\n",
    "train_y = train['unit_sales']\n",
    "train_weights = get_weights(train['item_nbr'])\n",
    "train_dataset = lgb.Dataset(train_X, label=train_y, weight=train_weights)\n",
    "bst = lgb.train(param, \n",
    "                train_dataset,\n",
    "                num_round,\n",
    "                feature_name=x_cols, \n",
    "                categorical_feature=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/pandas/core/generic.py:3643: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/home/ubuntu/grocery/model.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_prev[colname] = df_prev['unit_sales']\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('./data/test_processed.csv', dtype=types)\n",
    "test, _ = extend_dataset(test, items, stores)\n",
    "df_prev = extract_by_date(df, '2017-07-25', '2017-08-15')\n",
    "\n",
    "test, _ = fill_lagged(test, df_prev, 12, 18)\n",
    "test, _ = fill_mean_encoding(test, df_prev, combinations)\n",
    "test.perishable = test.perishable.astype('bool')\n",
    "\n",
    "test_X = test[x_cols]\n",
    "test['unit_sales'] = bst.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "test.sort_values(by='id', inplace=True)\n",
    "test.ix[test.unit_sales < 0, 'unit_sales'] = 0\n",
    "test['unit_sales'] = np.expm1(test['unit_sales'])\n",
    "test[['id', 'unit_sales']].to_csv('./submissions/lgb_mean_encoded_lagged_0.53.csv.gz', float_format=\"%.4f\", index=False, compression='gzip')\n",
    "!telegram-send \"Submission is done.\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
